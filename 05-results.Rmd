# Results

```{r }
library(tidyverse)
library(openintro)
library(agridat)
library(boot)
library(ggridges)
library(dplyr)
library(GGally)
library(plotly)
library(patchwork)
library(ggpubr)
library(grid)
library(gridExtra)
library(treemap)
library(viridis)

```


```{r}
data = read.csv('/Users/vedant/SpotifyAnalysis/dataset/Spotify_final_data.csv')
data = subset(data, select = -c(X))
```

#How does the danceability feature relate to songs produced in different eras? Do ppl
#dance to music produced in the current era or the preceding era?
```{r}
colsna = colSums(is.na(data)) %>%
  sort(decreasing = TRUE)

cols = colnames(data)
#Remove NA entries
data = data %>% filter(!is.na(playlist_name) & !is.na(track_album_name) & !is.na(track_album_id) & !is.na(track_album_release_date) & !is.na(tempo) & !is.na(danceability) & !is.na(energy) & !is.na(track_name) & !is.na(track_artist))
#Add a year column in the dataset
data$year = as.numeric(substring(data$track_album_release_date,1,4))
#removing unnecessary colums from the data 
data = data%>%dplyr::select(-track_id,-track_album_id,-playlist_id)

write.csv(data,"year_data.csv", row.names = FALSE)

# averaging the danceability values for all the year 
dance = data %>% group_by(year) %>% 
  summarise(avg_danceability = mean(danceability)) 
#Danceability trend over years

```

```{r}
maxx = c(max(dance$avg_danceability))
minn = c(min(dance$avg_danceability))

d = rbind(maxx,minn)
a = ggplot(dance, aes(x = year, y = avg_danceability)) + 
  geom_line(color = "#00AFBB", size = 1) + ylab('Average Danceability') + xlab('Year') +
  scale_x_continuous(breaks=seq(1950, 2020, 5)) 
ggplotly(a)

```
The Spotify dataset includes data from various years - 1955 to 2020. With the changing time, it is expected that the taste of music of the generation will change too. In the mission to determine the trend of music over the years and to understand if it's evolution has led in the production of 'more' danceable songs or less danceable songs, a following line graph has been plotted. The graph depicts the unusual rise and fall of danceable songs produced in each year. Geneally, the trend has been increasing and it is safe to conclude that with the passing year, the songs produced have a higher danceability factor. 

To compare the danceability of the two eras - 19th and 20th, it can be said that the 20th century produced songs constantly in the danceability range between 0.5 and 0.6. Whereas, in the 19th century, the distribution has been relatively uneven. The maximum is seen to rise beyond 0.8 and the minimum is below 0.4. Maybe the music producers have learned from this trend and are producing musics within a sweet spot range of 0.5 - 0.6.

Higest average danceability achieved - 0.816 in the year 1962

Lowest average danceability achieved - 0.317 in the year 1960



```{r}
genre_dance = data %>% group_by(playlist_genre) %>% select(danceability)
genre_dance_line = genre_dance %>% 
  group_by(playlist_genre) %>%
    summarize(avg = mean(danceability))

a = ggplot(genre_dance)+ geom_boxplot(aes(x = playlist_genre, y = danceability), fill = "cadetblue3") +
  geom_line(data = genre_dance_line, aes(x = playlist_genre, y = avg, group = 1), color = 'darkred') +
  theme_gray()
ggplotly(a)
```

```{r}


popartist = data %>%
  group_by(track_artist) %>%
  mutate(n = n()) %>%
  mutate(Freq = n/sum(n)) %>% filter(n > 95) %>% 
  select(track_artist, playlist_genre) 
popartist$num = 1

ggplot(popartist, aes(x =  track_artist, y = num, fill = playlist_genre)) + 
  geom_bar(stat = "identity") + xlab("Track artist") + ylab("Count") +
  scale_fill_brewer(palette = "Blues") + theme_classic()

```
To analyse the genres produced by the top 5 artists we have plotted a stacked bar chart to visualise the results. The plot can help us identify key factors like the genre preferences of an artist, the type of songs they have been producing, etc.

**Important information to artists/producers - **

It can also benefit the artist by understanding the competition in the music industry. They might want to study the genres produced by various artists and produce a one that is less common.

From the plot, we can see that the high producers of the edm genre are David Guetta, Martin Garrix, and The Chainsmokers. One can say that Don Oman produces most songs of Latin genre as compared to other genres. He is also the leading producer of this type of genre when compared with other top artists. Similarly, Queen produces rock type of music the most as compared to any other genres. They are specialised in the rock genre. Drake on the other hand has produced music of all genres in a somewhat similar proportion (higher preferences to rap and r&b). There seems to be direct competition between  David Guetta and The Chainsmokers as they produce a competitive number of songs belonging to the genres edm and pop.

**Leaders in each genres - **

Edm - Martin Garrix
Latin - Don Omar
Pop - The Chainsmokers/David Guetta
r&b - Drake
Rap - Drake
Rock - Queen
 

```{r}

dur = data %>% select(playlist_genre, year, duration_ms)

dur_pop = dur %>% filter(playlist_genre == 'pop') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))
dur_rap = dur %>% filter(playlist_genre == 'rap') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))
dur_rock = dur %>% filter(playlist_genre == 'rock') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))
dur_latin = dur %>% filter(playlist_genre == 'latin') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))
dur_rb = dur %>% filter(playlist_genre == 'r&b') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))
dur_edm = dur %>% filter(playlist_genre == 'edm') %>%  group_by(year, playlist_genre) %>% summarise(avg = mean(duration_ms))

a = rbind(dur_rb, dur_edm, dur_latin, dur_pop, dur_rock, dur_rap)

b = ggplot(a, aes(x = year, y = avg, colour = factor(playlist_genre))) + 
  geom_line(size = 1) + ylab('Avg Duration (ms)') + xlab('Year')+ theme_light() + facet_wrap(~playlist_genre)
ggplotly(b)

```
To understand the trend of various genres over time it is imperative we capture their average duration of being played in a given year. 

**Important information to artists/producers - **

The trend can convey important information to the artists and the producers of the song. It can tell if an artist should be working hard to produce a song of a particular genre or not. For example, as seen in the trend of the edm genre, it’s average duration of listening is tanking. It can be an indication that the audience prefers other genres over pop. An artist might therefore double question on the choice of a genre before finalizing one.

**Inferences - **

Several inferences can be drawn from the plot above - 

Latin - The trend followed by Latin is of a hill like, clinching one time high value of average duration of over 350000 in 1980s. The following years have been similar to that of the pop genre (with more drops). On a broader view, the trend has been on a fall  with few sharp ups and downs but maintaining the range between 200000 ms and 250000 ms. Again, it is one of the safe genres to produce. Despite a falling trend in recent years, it has been consistently over the 200000 ms mark.


r&b - The trend for r&b has been on a rise until 2010. Post 2010 captures a sudden drop in the average duration level and it continues to fall as the year progresses. However, between 1970 and 2010, the trend has been consistent and impressive, portraying an average duration of genre as high as 270000 ms. The consistent trend makes it the go to genre for producing songs for any artists/producers.

 
Rock - The average duration for rock has been consistent throughout the years (after 1970). The genre has successfully maintained its average duration range between 220000 to 270000. The highest was achieved at over 300000 in the year 1970. Rock is a great genre choice for artists as it yields considerable interests in the listeners as is reflected in the plot. 


Rap - Similar to the trend of pop, the rap genre was quite popular until 2010 and it’s average duration has been on a decline ever since. The rap genre managed to exceed the average duration of 400000 ms, second after the edm genre. The trend however, doesn’t bode well for the rap genre as it continues to sink to it’s all time low duration of under 200000 ms. To conclude, a versatile artist might be a little sceptical about producing the rap genre and would prefer other genres belonging to his repertoire.


edm - The trend of average duration played per year is not consistent with irregular rise and drop at different intervals. It can be interpreted that the demand of edm was the  most between the year 1995 and 2010.This can be deemed as a successful era for the edm artists as the average duration in ms has crossed 300000 multiple times and achieved a high of over 450000 ms. Although the graph indicates a dip in the later half of the 2010, the duration of edm still surpasses other genres. To conclude, from the trend it can be attested that the emd genre is the safest to produce and the artists can benefit from it.


Pop - The trend of average duration played per year can be split in two trends - 19th century and 20th century. It can be seen that the overall demand for pop was greater in the 19th century with maximum average duration crossing 300000 ms and lowering at 150000 ms. The demand for the 20th century has been pretty consistent with the curve dipping after 2014 indicating lower demand. The maximum average duration during this century touches 250000 ms and tanks the least at 200000 ms. To conclude, the artists can safely produce more songs of the pop genre considering it’s trend post year 2000 is pretty consistent.



```{r}
words = data %>% select(playlist_genre, instrumentalness, speechiness)

ggplot(words, aes(x = instrumentalness, y = speechiness)) + geom_point() + 
  geom_smooth(method = lm) + facet_wrap(~playlist_genre) + theme_light()
```
Before interpreting the above plot, it is important to understand the meaning of the two words - speechiness and instrumentalness.

**As described by tidytuesday - **

*Instrumentalness conveys whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Spoken words or Rap are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.

Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.*

A normal assumption around any music is that if the song contains high number of words, it’s instrumentalness is bound to be low. However, for various genres, it is seen that the relation between speehiness and instrumentalness is a line of slope nearly 0. For rap, a different trend can be seen. A plot with negative line slope indicates a negative coorelation, i.e, with increase in the value of speechiness, the instrumentalness decreases.  


```{r}

d1 = data %>% select(energy, liveness, playlist_genre)

p = ggplot(d1, aes(liveness, energy, colour = factor(playlist_genre))) + 
  geom_density_2d() + facet_wrap(~playlist_genre) + theme_light()
ggplotly(p)


```

To see the distribution of energy and liveness for various genres,  a scatter plot is plotted. The plot can help us understand the space at which the data is cluttered the most and the spread of the data.

These plots can be inaluable when we want to understand what genre yeilds maximum liveness or energy. This is especially  important for music festivals/clubs where the songs to be played are of high energy and liveness.

**The following inferences can be drawn out of this plot - **

For edm, the range of liveness is between 0 and 0.3 and the range of energy is between 0.6 and 1
For latin, the range of liveness is between 0.05 and 0.2 and the range of energy is between 0.47 and 0.8
For pop, the range of liveness is between 0.04 and 0.2 and the range of energy is between 0.6 and 0.9
For r&b, the range of liveness is between 0.03 and 0.17 and the range of energy is between 0.2 and 0.86
For rap, the range of liveness is between 0.04 and 0.2 and the range of energy is between 0.3 and 0.9
For rock, the range of liveness is between 0.02 and 0.25 and the range of energy is between 0.4 and 0.95



```{r}
a = data %>% select(track_name,acousticness,speechiness,energy,danceability,loudness)%>% group_by(track_name) %>% 
  summarise(count = n(), acousticness = mean(acousticness),speechiness = mean(speechiness), energy = mean(energy),danceability = mean(danceability)) %>% arrange(desc(count)) 

a = head(a, 5) %>% select(!count)
a = a %>% pivot_longer(!track_name, names_to = "Variables", values_to = "Values")

ggplot(data=a, aes(x=Variables, y=Values))+geom_bar(aes(y=Values, fill=track_name),stat="identity", alpha=0.8 , position="dodge", colour = 'black')+ ylab("Value")+ xlab("Variables of a song")+ggtitle("Top 5 songs in Spotify 2018 ")+
  scale_fill_brewer(palette = "Blues") + theme_light()
```

It's always exciting to listen to a trendy song. But how many of us have identified the parameters/qualities that these songs entail. More often than not, we fail to identify the various qualities these songs convey. It was therefore an exciting task to visualise the top 5 songs and compare them on various grounds. We plotted a grouped bar chart of the top 5 songs played with factors like - acousticness, danceability, energy,and speechiness. A general trend can be seen. All the top 5 songs have low values of acousticness and speechiness and high values of energy and danceability. This tells a lot about the kind of songs that are most heard. They are more energetic and are fun to dance on. It is something that the generation prefers. If the artists happen to come across these visualisations, they will know the secret to produce the song that makes it to the top.

In this plot, Alive and Forever have the highest value of energy equal to 0.78. While more energy might hint for higher danceability, the visualisation portrays otherwise. Breathe and Forever have the highest value of danceability equal to 0.62. Another interesting fact to notice is that all the top 5 songs have low speechiness value. These songs have low words to music - something enjoyed by the 20th generation population.

**Songs with the highest song of variables - **

acousticness - Stay
danceability - Stay and Breathe
energy - Forever and Alive
speechiness - Forever

**Songs with the lowest value of song variables - **

acousticness - Alive
danceability - Poisoan
energy - Stay
speechiness - Stay and Alive



```{r}
ms = data %>% select(playlist_genre, year, mode, duration_ms)
ms = ms %>% group_by(playlist_genre) %>% mutate(avg_dur = mean(duration_ms))
ms$year = ifelse(ms$year >= 2000, '20th','19th')
ms$avg_dur = ifelse(ms$avg_dur >= 220000, '220k+','220k-')
ms = ms %>% select(playlist_genre,year,avg_dur)
vcd::mosaic(year ~ playlist_genre,
            highlighting_fill = c("grey90", "cornflowerblue"), ms,
            direction = c("v", "h"))


#d = data %>% group_by(year) %>% select(year)
#d$year = ifelse(d$year >= 2000, 19,20)
#d = head(d,1000) %>% select(year)
#d = d %>% group_by(year) %>% select(year)
#d = head(d,20000) %>% select(year)
#table(d)

ms = data %>% select(playlist_genre, year, mode, duration_ms)
ms = ms %>% group_by(playlist_genre) %>% mutate(avg_dur = mean(duration_ms))
ms$year = ifelse(ms$year >= 2000, '20th','19th')
ms19 = ms %>% filter(year == '19th' && avg_dur > 220000)
ms20 = ms %>% filter(year == '20th' && avg_dur < 220000)
ms19 = head(ms19, 1000)
ms20 = head(ms20,600)
msf = rbind(ms19,ms20)
msf$avg_dur = ifelse(msf$avg_dur >= 220000, '220k+','220k-')
vcd::mosaic(avg_dur ~ year + playlist_genre, direction = c("v", "h", "v"),
            highlighting_fill = c("grey90", "cornflowerblue", 'yellow'), msf)
```




```{r}

library(RColorBrewer)
fills6 <- rev(brewer.pal(6,'Blues'))

popartist = data %>%
  group_by(track_artist) %>%
  mutate(n = n()) %>%
  mutate(Freq = n/sum(n)) %>% filter(n > 110) %>% 
  select(track_artist, playlist_genre,duration_ms) 

popartist$duration_ms = ifelse(popartist$duration_ms >= 220000, '200k+','220k-')

vcd::mosaic(playlist_genre ~ track_artist + duration_ms, direction = c("v", "v", "h"),
           highlighting_fill = rev(fills6), popartist) + theme_light()


```
To understand the distribution of the music produced by the top 3 artists and their duration in ms, a mosaic plot is plotted. The mosaic plot is split on the three basics - duration of songs produced by the top3 artists, genres of the songs, and the top 3 artists.  We can break the information depicted by the mosaic plots as follows - 

Firstly, we split the data based on the duration heard. We can see that for Martin Garrix, there are more songs produced by him that have been heard over 220k times when compared to songs heard below 220k.

For Queen and Chainsmokers, songs that have been heard below 220k times is greater than songs heard beyond 220k times.
 
Queen has been a lead producer of songs of rock genre, Chainsmoker have been a lead producer of the pop genre, and Martin Garrix has been a lead producer of the edm genre.

This representation can guide the artists about their overall performance and help them gauge their success based on the duration of the songs heard.



```{r}

pop = data %>%
  group_by(track_artist) %>%
  mutate(n = n()) %>%
  mutate(Freq = n/sum(n)) %>% filter(n > 100) %>% 
  select(track_artist, track_name,energy, loudness, liveness,valence, speechiness,danceability,playlist_genre) 

a = pop %>% group_by(track_name) %>% mutate(count = n())

names = c("David Guetta", "The Chainsmokers", "Martin Garrix", "Queen", "Don Omar")

#x = data %>% filter(track_artist == i) 

x1 = data %>% filter(track_artist == "David Guetta") %>% mutate(num = 1) %>% select(track_name,energy, loudness, liveness,valence, speechiness,danceability, playlist_genre )
y1 = x1 %>% group_by(track_name) %>% mutate(count = n()) %>% arrange(desc(count))
y1$track_artist ="David Guetta"
write.csv(a,"david.csv", row.names = FALSE)

x2 = data %>% filter(track_artist == "The Chainsmokers") %>% mutate(num = 1)%>% select(track_name,energy, loudness, liveness,valence, speechiness,danceability, playlist_genre )
y2 = x2 %>% group_by(track_name) %>% mutate(count = n()) %>% arrange(desc(count))
y2$track_artist ="The Chainsmokers"
write.csv(a,"chainsmokers.csv", row.names = FALSE)

x3 = data %>% filter(track_artist == "Martin Garrix") %>% mutate(num = 1)%>% select(track_name,energy, loudness, liveness,valence, speechiness,danceability, playlist_genre )
y3 = x3 %>% group_by(track_name) %>% mutate(count = n()) %>% arrange(desc(count))
y3$track_artist ="Martin Garrix"
write.csv(a,"garrix.csv", row.names = FALSE)

x4 = data %>% filter(track_artist == "Queen") %>% mutate(num = 1)%>% select(track_name,energy, loudness, liveness,valence, speechiness,danceability, playlist_genre, playlist_genre )
y4 = x4 %>% group_by(track_name) %>% mutate(count = n()) %>% arrange(desc(count))
y4$track_artist ="Queen"
write.csv(a,"queen.csv", row.names = FALSE)

x5 = data %>% filter(track_artist == "Don Omar") %>% mutate(num = 1)%>% select(track_name,energy, loudness, liveness,valence, speechiness,danceability, playlist_genre )
y5 = x5 %>% group_by(track_name) %>% mutate(count = n()) %>% arrange(desc(count))
y5$track_artist ="Don Omar"
write.csv(a,"omar.csv", row.names = FALSE)

a = rbind(y1,y2,y3,y4,y5)
a = a %>% filter(loudness > -5)
write.csv(a,"d3Data.csv", row.names = FALSE)

```

```{r}


x1 = pop %>% filter(playlist_genre == "pop") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x1 = head(x1,15)
write.csv(x1, "pop.csv", row.names = FALSE)

x2 = pop %>% filter(playlist_genre == "rap") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x2 = head(x2,15)
write.csv(x2, "rap.csv", row.names = FALSE)

x3 = pop %>% filter(playlist_genre == "rock") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x3 = head(x3,15)
write.csv(x3, "rock.csv", row.names = FALSE)

x4 = pop %>% filter(playlist_genre == "latin") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x4 = head(x4,15)
write.csv(x4, "latin.csv", row.names = FALSE)

x5 = pop %>% filter(playlist_genre == "r&b") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x5 = head(x5,15)
write.csv(x5, "r&b.csv", row.names = FALSE)

x6 = pop %>% filter(playlist_genre == "edm") %>% group_by(track_name,energy, liveness,valence, speechiness,danceability, track_artist,playlist_genre) %>% summarise(count = n()) %>% arrange(desc(count))
x6 = head(x6,15)

write.csv(x6, "edm.csv", row.names = FALSE)
a = rbind(x1,x2,x3,x4,x5,x6)
write.csv(a,"datad3.csv", row.names = FALSE)

chain = a %>% filter(track_artist == "The Chainsmokers")
queen = a %>% filter(track_artist == "Queen")
don = a %>% filter(track_artist == "Don Omar")
mar = a %>% filter(track_artist == "Martin Garrix")
david = a %>% filter(track_artist == "David Guetta")

write.csv(chain, "chain.csv", row.names = FALSE)
write.csv(queen, "queen.csv", row.names = FALSE)
write.csv(don, "don.csv", row.names = FALSE)
write.csv(mar, "mar.csv", row.names = FALSE)
write.csv(david, "david.csv", row.names = FALSE)



```

```{r}


popartist = data %>%
  group_by(track_artist) %>%
  mutate(n = n()) %>%
  mutate(Freq = n/sum(n)) %>% filter(n > 60) %>% 
  select(track_artist, playlist_genre) 

a = data.frame(unique(popartist$track_artist))

```


```{r}

# Ridge density plot for Dancibility/ Energy/ Loudness / Speechiness for each genre
  
library(ggridges)

data1 = data %>% select(energy, danceability, playlist_genre, speechiness, loudness, track_popularity) %>% filter(track_popularity> 70)

g1 <- data1 %>% ggplot() + 
  geom_density_ridges(aes(danceability , playlist_genre,fill = playlist_genre), alpha = .3) + 
  ylab("Playlist Genre") + 
  xlab("Dancibility") +
  ggtitle("Dancibility")

g2 <- data1 %>% ggplot() + 
  geom_density_ridges(aes(energy, playlist_genre, fill = playlist_genre),alpha = .3) +
  ylab("Playlist Genre") + 
  xlab("Energy") +
  ggtitle("Energy")

g3 <- data1 %>% ggplot() + 
  geom_density_ridges(aes(loudness, playlist_genre, fill = playlist_genre), alpha = .3) +
  ylab("Playlist Genre") + 
  xlab("Loudness") +
  ggtitle("Loudness")

g4 <- data1 %>% ggplot() + 
  geom_density_ridges(aes(speechiness, playlist_genre, fill = playlist_genre), alpha = .3) +
  ylab("Playlist Genre") + 
  xlab("SPeechiness") +
  ggtitle("Speechiness")


p <- ggarrange(g1, g2, g3, g4, ncol=2, nrow = 2,  common.legend = TRUE, legend="bottom")

annotate_figure(p, top = textGrob("Ridge Density plot for each genre",gp=gpar(fontsize=15)))


```
In the graph below we used ridge regression since, we the spotify playlist genre had multiple attributes against each of the music charecteristics - Dancebility, Energy, loudness and speechiness.

For dancebility, it can be inferred that the graphs for all the genres are nearly uniformally distributed. Listenrs of rap and latin music usually enjoy dancing to the beats whereas edm and rock music despite generating most energy amongst the listenrs is not preferred for dancing. 

For energy, the distributtions are less uniform and more skewed towards the left. Rock and Edm genre usually produce high intensity music and hence listerns higher levels of energy listening to these genres. It can be seen that r&b has the most uniform grpahs showing that its music has a mix of low and high intensity songs i.e both slow, soft and loud , fast. Hence we can see such wide distribution in case of r&b. 

For loudness it can be seen that all the genres produce songs of a similar amplitude. Usually loduness can be related with energy. Genres such as edm and rock are mostly composed of loud music and hence is an important characteristic in inflicting high energy amongst its listeners. 

From speechiness it can be inferred that most of the listeners of this spotify dataset enjoy listening to more instrumental and less of spoken words. Since rap music is one of the most popular type of vocal music. hence its distribution is more evenly spaced out incomparision to other genres.   

Using this visualisation, artists can use the trusted speechiness. loudness values which will keep the fans hooked on their songs. Understanding a perfect blend of different different song parameters beyond this graph will ensure higher dancebility and energy amongst the listernes and eventually make them and their songs popular. 

```{r}
# treemap depicts top 15 track artists with in each of the 6 playlist genre. The size of the boxes in treemap corresponds to the count tracks for the artists.
library(treemap) 
library(viridis)
top_genre <- data %>% select(playlist_genre, track_artist, track_popularity) %>% group_by(playlist_genre,track_artist) %>% summarise(n = n()) %>% top_n(15, n)

tm <- treemap(top_genre, index = c("playlist_genre", "track_artist"), vSize = "n", vColor = 'playlist_genre', palette =  viridis(6),title="Top 15 Track Artists within each Playlist Genre")

```

Here to depict the top 15 artists in each of the 6 playlist genre, we used a Treemap. The different colors demarcate the different genres whereas the size of the boxes in the treemap corresponds to the number of tracks played by listeners of an artist. Listeners of edm music clearly show more affection towards the songs produced by Martin Garrix, Dimitri Vegas & Like Mike and Hardwell. For all the other artists there is no dominance. 

Similar preferrance can be seen for Queen and Guns N Roses band in rock and Don Omar, Daddy Yankee and Wisin and Yandel in Latin. For songs that fall in the genre of Pop and r&b, the listeners have a diverse choice and no band or group of musicians are dominating. It can also be observed that a lot of artists/groups that are popular in edm have shown remarkable popularity in pop. For example- David Guetta and Calvin Harris are amongst the few artists to feature in more than 1 genree of top 15 artists. 

Lastly based on the overall size, it can be seen that edm and rap cover a larger area of treemap thus indicating that these genres are most popular along the other 4 genres. While, pop and r&b show lower popularity amongst the listeners of the spotify dataset. 

This visualisation can help artists keep track of other popular artists in different genres. This can also help them understand which artists/bands to look upto i.e their advertisement/ marketing strategies et al. if they plan on releasing songs outside of their genre.

```{r}

  minutesMostListened = data %>% 
  group_by(track_artist) %>% 
  summarize(minutesListened = sum(duration_ms)/60000) %>% 
  filter(minutesListened >= 180) %>%
  ggplot(aes(x = track_artist, y = minutesListened)) + 
  geom_col(aes(fill = minutesListened)) +
  scale_fill_gradient(low = "yellow", high = "red") + 
  labs(x= "Artist", y= "Minutes of music playback") + 
  ggtitle("What were the most listened artists on my Spotify dataset?", "> 3 hours listened") +
  theme(axis.text.x = element_text(angle = 90))
minutesMostListened

```
Here we have plotted a heatmap showing hot and cold regions between various attributes of the dataset. For track popularity > = 0.5, heatmap helps us to visualise the relation between the various attributes. For eg, songs that inflict a sense of energy, have a higher dancebility factor. 

Furthermore, it is observed that too short or too long duration songs do not energise the listeners. Listeners prefer songs that last for a minimum duration of 200 seconds and goes to a high of 300 seconds. 


This graph shows us the most listened artist in the spotify dataset. Since, we had more than a thousand artists, filtering the data by duration helped us segregate the artists whose songs were heard for more than hours. The histogram is used to compare the  popularity amongst artists. Matrin Garrix that was popular both in pop and edm genre and hence is played for the longest duration by its neighbors.

Using such data, spotify can work on its marketing strategy to check on ways of improving recognition almongst the less prominent artists. This can be done by showing more advertisements or song suggestions of the lesser popular singers so that listerners listen to them. Such stategy will make listeners spend more time on the spotify platform and can potentially increase their revenue. 

```{r}
feature_names <- names(data)[9:20]


data_corr = data %>%
  dplyr::select(feature_names) %>%
  scale() %>%
  cor() %>%
  corrplot::corrplot(method = 'color', 
                     order = 'hclust', 
                     type = 'upper', 
                     diag = FALSE, 
                     tl.col = 'black',
                     addCoef.col = "grey30",
                     number.cex = .7,
                     col = colorRampPalette(colors = c('red','white','blue'))(200),
                     main = 'Audio Feature Correlation',
                     mar = c(2,2,2,2),
                     family = 'Avenir',
                     number.digits = 1.
                     
                     )
                     
```
In the audio feature correlation map, energy and loudness seem to be positively correlated

```{r}
feature_names <- names(data)[9:20]


data_corr = data %>%
  dplyr::select(feature_names) %>%
  scale() %>%
  cor() %>%
  corrplot::corrplot(method = 'color', 
                     order = 'hclust', 
                     type = 'upper', 
                     diag = FALSE, 
                     tl.col = 'black',
                     addCoef.col = "grey30",
                     number.cex = .7,
                     col = colorRampPalette(colors = c('red','white','blue'))(200),
                     main = 'Audio Feature Correlation',
                     mar = c(2,2,2,2),
                     family = 'Avenir',
                     number.digits = 1.
                     
                     )
```

```{r}

p1 <- data %>% ggplot(aes(x = playlist_genre, y = valence, color = playlist_genre)) +
  geom_boxplot(alpha = 0.7, notch = TRUE) +
  theme_bw() +
  labs(title = 'How happy or sad the genres are?', x= 'Genres', y = 'Happiness' )

#Energy

p2 <- data %>% ggplot(aes(x = playlist_genre, y = energy, color = playlist_genre)) +
  geom_boxplot(alpha = 0.1, notch = TRUE) +
  theme_bw() +
  labs(title = 'How energetic are the Genres?', x= 'Genres', y = 'Energy' )

#Danceability
p3 <- data %>% ggplot(aes(x = playlist_genre, y = danceability, color = playlist_genre)) +
  geom_boxplot(alpha = 0.5, notch = TRUE) +
  theme_bw() +
  labs(title = 'Genres and their danceablity', x= 'Genres', y = 'Danceability' )

#Tempo
p4 <- data %>% ggplot(aes(x = playlist_genre, y = tempo, color = playlist_genre)) +
  geom_boxplot(alpha = 0.5, notch = TRUE) +
  theme_bw() +
  labs(title = 'Genres and their Tempo', x= 'Genres', y = 'Tempo' )

ggarrange(p1,p2,p3,p4 , nrow = 2, ncol = 2, common.legend = TRUE, legend="bottom")

```

How does boxplots and density plots together help us understand generes and their features?

Valence - As observed in the density plot valence can provide us a good seperation between EDM and Latin tracks as their is a comsiderable difference between their medial values and range, while all other genres have somewhat similar valence.

Energy - Latin and Pop tracks have similar range and median values so energy might not be a good seperator for them while the remaining 4 genres have a decent seperation on energy.

Danceability - As density plots show Rock has the lowest danceability score while Latin tracks are more closely packed with the high danceability scores and Rap have a little more variability than latin tracks but in general have high danceability score.

Tempo - It might do a good job of seperating EDM tracks from the rest of the genres as most of the EDM tracks are clustered around 125 while other genres have more or less a similar spread and variability.

```{r}
  minutesMostListened = data %>% 
  group_by(track_artist) %>% 
  summarize(minutesListened = sum(duration_ms)/60000) %>% 
  filter(minutesListened >= 180) %>%
  ggplot(aes(x = track_artist, y = minutesListened)) + 
  geom_col(aes(fill = minutesListened)) +
  scale_fill_gradient(low = "yellow", high = "red") + 
  labs(x= "Artist", y= "Minutes of music playback") + 
  ggtitle("What were the most listened artists on my Spotify?", "> 3 hours listened") +
  theme(axis.text.x = element_text(angle = 90))
minutesMostListened

```

This graph shows us the most listened artist in the spotify dataset. Since, we had more than a thousand artists, filtering the data by duration helped us segregate the artists whose songs were heard for more than hours. The histogram is used to compare the  popularity amongst artists. Matrin Garrix that was popular both in pop and edm genre and hence is played for the longest duration by its neighbors.

Using such data, spotify can work on its marketing strategy to check on ways of improving recognition almongst the less prominent artists. This can be done by showing more advertisements or song suggestions of the lesser popular singers so that listerners listen to them. Such stategy will make listeners spend more time on the spotify platform and can potentially increase their revenue.

